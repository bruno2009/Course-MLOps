{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf, linewidth=200, formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    root_mean_squared_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import (\n",
    "    fmin,  # Function for minimizing/maximizing an objective function\n",
    "    tpe,   # Tree-structured Parzen Estimator (TPE) algorithm for optimization\n",
    "    hp,    # Defines search space for hyperparameters\n",
    "    STATUS_OK,  # Constant indicating successful completion of an objective\n",
    "    Trials  # Container for storing results of each trial\n",
    ")\n",
    "\n",
    "\n",
    "from hyperopt.pyll import scope # Handles scoping in hyperparameter definitions\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\") # sets the sqlite up for storing artifacts\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\") # this is the experiment. It will try to recognize if the experiment exist and, If not, it will create a new one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('./data/green_tripdata_2021.parquet')\n",
    "\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying if a categorical variable is a string.\n",
    "# categorical = ['VendorID', 'trip_type']\n",
    "categorical = ['trip_type', 'RatecodeID']\n",
    "numerical = ['trip_distance']\n",
    "label = ['duration']\n",
    "\n",
    "categorical_columns = [col for col in categorical if col in df.columns]\n",
    "\n",
    "for column in categorical_columns:\n",
    "    if df[column].dtype == 'category':\n",
    "        print(f\"{column} is already of type str\")\n",
    "    else:\n",
    "        print(f\"{column} is not of type str\")\n",
    "        df[column] = df[column].astype('category')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[categorical + numerical]\n",
    "y = df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_split, y_train, y_split = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_split, y_split, test_size=0.4, random_state=42)\n",
    "\n",
    "print('Lengh train X and y: ', X_train.shape,' ', len(y_train))\n",
    "print('Lengh valid X and y: ', X_val.shape,'  ', len(y_val))\n",
    "print('Lengh test  X and y: ', X_test.shape,'  ', len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ”c”, which represents categorical columns.\n",
    "# ”q”, which represents numeric columns.\n",
    "# ”int”, which represents integer columns.\n",
    "# ”i”, which represents boolean columns.\n",
    "\n",
    "# ft = [\"c\", \"c\", \"q\"]\n",
    "# train = xgb.DMatrix(X_train, label=y_train, enable_categorical=True, feature_types = ft)\n",
    "\n",
    "train = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "valid = xgb.DMatrix(X_val,   label=y_val,   enable_categorical=True)\n",
    "test = xgb.DMatrix(X_test,   label=y_test,  enable_categorical=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DMatrix to Pandas DataFrame\n",
    "train.get_data().toarray()\n",
    "df = pd.DataFrame(train.get_data().toarray(), columns=[f'feature_{i}' for i in train.feature_names ])\n",
    "df['label'] = train.get_label()\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df['feature_RatecodeID'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Linear regression***\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, name_set = \"xgboost\"):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", name_set)\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "\n",
    "        y_pred_val = booster.predict(valid)\n",
    "        rmse_val = root_mean_squared_error(y_val, y_pred_val)\n",
    "        mlflow.log_metric(\"rmse_val\", rmse_val)\n",
    "\n",
    "        y_pred_test = booster.predict(test)\n",
    "        rmse_test = root_mean_squared_error(y_test, y_pred_test)\n",
    "        mlflow.log_metric(\"rmse_test\", rmse_test)\n",
    "\n",
    "    return {'loss': rmse_val, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -6, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:squarederror',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# best_result = fmin(\n",
    "#     fn=objective,\n",
    "#     space=search_space,\n",
    "#     algo=tpe.suggest,\n",
    "#     max_evals=50,\n",
    "#     trials=Trials()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Gamma Regression***\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_gamma = partial(objective, name_set=\"xgboost-gamma\")\n",
    "\n",
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -6, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:gamma',\n",
    "    'seed': 42,\n",
    "    'eval_metric': 'gamma-nloglik'\n",
    "}\n",
    "\n",
    "# best_result = fmin(\n",
    "#     fn=objective_gamma,\n",
    "#     space=search_space,\n",
    "#     algo=tpe.suggest,\n",
    "#     max_evals=50,\n",
    "#     trials=Trials()\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow\n",
    "# Parameter           Value\n",
    "# eval_metric         gamma-nloglik\n",
    "# learning_rate       0.01009913729679454\n",
    "# max_depth           4\n",
    "# min_child_weight    10.112031917109253\n",
    "# objective           reg:gamma\n",
    "# reg_alpha           0.318404154187771\n",
    "# reg_lambda          0.0050144697269259636\n",
    "# seed                42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_final = {\n",
    "'learning_rate': 0.01009913729679454,\n",
    " 'max_depth': int(4),\n",
    " 'min_child_weight': 10.112031917109253,\n",
    " 'reg_alpha': 0.318404154187771,\n",
    " 'reg_lambda': 0.0050144697269259636,\n",
    " 'objective': 'reg:gamma',\n",
    " 'seed': 42,\n",
    " 'eval_metric': 'gamma-nloglik'}\n",
    "\n",
    "\n",
    "# Autologging is known to be compatible with the following package versions: 1.4.2 <= xgboost <= 2.0.3. \n",
    "# Autologging may not succeed when used with package versions outside of this range.\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "train = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "valid = xgb.DMatrix(X_val,   label=y_val,   enable_categorical=True)\n",
    "test = xgb.DMatrix(X_test,   label=y_test,  enable_categorical=True)\n",
    "\n",
    "booster = xgb.train(\n",
    "    params=params_final,\n",
    "    dtrain=train,\n",
    "    num_boost_round=1000,\n",
    "    evals=[(valid, 'validation')],\n",
    "    early_stopping_rounds=50\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
