{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf, linewidth=200, formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    root_mean_squared_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import (\n",
    "    fmin,  # Function for minimizing/maximizing an objective function\n",
    "    tpe,   # Tree-structured Parzen Estimator (TPE) algorithm for optimization\n",
    "    hp,    # Defines search space for hyperparameters\n",
    "    STATUS_OK,  # Constant indicating successful completion of an objective\n",
    "    Trials  # Container for storing results of each trial\n",
    ")\n",
    "\n",
    "\n",
    "from hyperopt.pyll import scope # Handles scoping in hyperparameter definitions\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/25 15:08:16 INFO mlflow.tracking.fluent: Experiment with name 'nyc-taxi-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/bruno/Git/Course-MLOps/02-intro/mlruns/1', creation_time=1721916496215, experiment_id='1', last_update_time=1721916496215, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\") # sets the sqlite up for storing artifacts\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\") # this is the experiment. It will try to recognize if the experiment exist and, If not, it will create a new one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost version: 2.0.3\n",
      "MLflow version: 2.14.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lpep_pickup_datetime     False\n",
       "lpep_dropoff_datetime    False\n",
       "RatecodeID               False\n",
       "PULocationID             False\n",
       "DOLocationID             False\n",
       "trip_distance            False\n",
       "VendorID                 False\n",
       "trip_type                False\n",
       "duration                 False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('./data/green_tripdata_2021.parquet')\n",
    "\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip_type is not of type str\n",
      "RatecodeID is not of type str\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lpep_pickup_datetime     datetime64[us]\n",
       "lpep_dropoff_datetime    datetime64[us]\n",
       "RatecodeID                     category\n",
       "PULocationID                      int64\n",
       "DOLocationID                      int64\n",
       "trip_distance                   float64\n",
       "VendorID                          int64\n",
       "trip_type                      category\n",
       "duration                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying if a categorical variable is a string.\n",
    "# categorical = ['VendorID', 'trip_type']\n",
    "categorical = ['trip_type', 'RatecodeID']\n",
    "numerical = ['trip_distance']\n",
    "label = ['duration']\n",
    "\n",
    "categorical_columns = [col for col in categorical if col in df.columns]\n",
    "\n",
    "for column in categorical_columns:\n",
    "    if df[column].dtype == 'category':\n",
    "        print(f\"{column} is already of type str\")\n",
    "    else:\n",
    "        print(f\"{column} is not of type str\")\n",
    "        df[column] = df[column].astype('category')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[categorical + numerical]\n",
    "y = df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengh train X and y:  (22232, 3)   22232\n",
      "Lengh valid X and y:  (8893, 3)    8893\n",
      "Lengh test  X and y:  (5929, 3)    5929\n"
     ]
    }
   ],
   "source": [
    "X_train, X_split, y_train, y_split = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_split, y_split, test_size=0.4, random_state=42)\n",
    "\n",
    "print('Lengh train X and y: ', X_train.shape,' ', len(y_train))\n",
    "print('Lengh valid X and y: ', X_val.shape,'  ', len(y_val))\n",
    "print('Lengh test  X and y: ', X_test.shape,'  ', len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trip_type        category\n",
       "RatecodeID       category\n",
       "trip_distance     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ”c”, which represents categorical columns.\n",
    "# ”q”, which represents numeric columns.\n",
    "# ”int”, which represents integer columns.\n",
    "# ”i”, which represents boolean columns.\n",
    "\n",
    "# ft = [\"c\", \"c\", \"q\"]\n",
    "# train = xgb.DMatrix(X_train, label=y_train, enable_categorical=True, feature_types = ft)\n",
    "\n",
    "train = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "valid = xgb.DMatrix(X_val,   label=y_val,   enable_categorical=True)\n",
    "test = xgb.DMatrix(X_test,   label=y_test,  enable_categorical=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_trip_type  feature_RatecodeID  feature_trip_distance      label\n",
      "0                0.0                 0.0                   6.95  17.383333\n",
      "1                0.0                 0.0                   1.40   6.666667\n",
      "2                0.0                 0.0                   1.50   7.566667\n",
      "3                0.0                 0.0                   1.58   7.166667\n",
      "4                0.0                 0.0                   1.80  10.266666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.000,  4.000,  1.000,  3.000,  2.000], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert DMatrix to Pandas DataFrame\n",
    "train.get_data().toarray()\n",
    "df = pd.DataFrame(train.get_data().toarray(), columns=[f'feature_{i}' for i in train.feature_names ])\n",
    "df['label'] = train.get_label()\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df['feature_RatecodeID'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Linear regression***\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, name_set = \"xgboost\"):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", name_set)\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "\n",
    "        y_pred_val = booster.predict(valid)\n",
    "        rmse_val = root_mean_squared_error(y_val, y_pred_val)\n",
    "        mlflow.log_metric(\"rmse_val\", rmse_val)\n",
    "\n",
    "        y_pred_test = booster.predict(test)\n",
    "        rmse_test = root_mean_squared_error(y_test, y_pred_test)\n",
    "        mlflow.log_metric(\"rmse_test\", rmse_test)\n",
    "\n",
    "    return {'loss': rmse_val, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -6, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:squarederror',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# best_result = fmin(\n",
    "#     fn=objective,\n",
    "#     space=search_space,\n",
    "#     algo=tpe.suggest,\n",
    "#     max_evals=50,\n",
    "#     trials=Trials()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_result\n",
    "\n",
    "# {'learning_rate': 0.008611076311094068,\n",
    "#  'max_depth': 4.0,\n",
    "#  'min_child_weight': 18.488225034580513,\n",
    "#  'reg_alpha': 0.29662061225495734,\n",
    "#  'reg_lambda': 0.0371065942542032}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Gamma Regression***\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_gamma = partial(objective, name_set=\"xgboost-gamma\")\n",
    "\n",
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -6, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:gamma',\n",
    "    'seed': 42,\n",
    "    'eval_metric': 'gamma-nloglik'\n",
    "}\n",
    "\n",
    "# best_result = fmin(\n",
    "#     fn=objective_gamma,\n",
    "#     space=search_space,\n",
    "#     algo=tpe.suggest,\n",
    "#     max_evals=50,\n",
    "#     trials=Trials()\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.08055973081693549,\n",
       " 'max_depth': 4.0,\n",
       " 'min_child_weight': 15.76289220268423,\n",
       " 'reg_alpha': 0.10079556317337575,\n",
       " 'reg_lambda': 0.04834019493231889}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_result\n",
    "\n",
    "\n",
    "# Parameter           Value\n",
    "# eval_metric         gamma-nloglik\n",
    "# learning_rate       0.08055973081693549\n",
    "# max_depth           4\n",
    "# min_child_weight    15.76289220268423\n",
    "# objective           reg:gamma\n",
    "# reg_alpha           0.10079556317337575\n",
    "# reg_lambda          0.04834019493231889\n",
    "# seed                42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-gamma-nloglik:5.97515\n",
      "[1]\tvalidation-gamma-nloglik:5.72177\n",
      "[2]\tvalidation-gamma-nloglik:5.49132\n",
      "[3]\tvalidation-gamma-nloglik:5.28188\n",
      "[4]\tvalidation-gamma-nloglik:5.09180\n",
      "[5]\tvalidation-gamma-nloglik:4.91933\n",
      "[6]\tvalidation-gamma-nloglik:4.76303\n",
      "[7]\tvalidation-gamma-nloglik:4.62154\n",
      "[8]\tvalidation-gamma-nloglik:4.49360\n",
      "[9]\tvalidation-gamma-nloglik:4.37805\n",
      "[10]\tvalidation-gamma-nloglik:4.27379\n",
      "[11]\tvalidation-gamma-nloglik:4.17984\n",
      "[12]\tvalidation-gamma-nloglik:4.09527\n",
      "[13]\tvalidation-gamma-nloglik:4.01922\n",
      "[14]\tvalidation-gamma-nloglik:3.95094\n",
      "[15]\tvalidation-gamma-nloglik:3.88971\n",
      "[16]\tvalidation-gamma-nloglik:3.83487\n",
      "[17]\tvalidation-gamma-nloglik:3.78581\n",
      "[18]\tvalidation-gamma-nloglik:3.74201\n",
      "[19]\tvalidation-gamma-nloglik:3.70296\n",
      "[20]\tvalidation-gamma-nloglik:3.66819\n",
      "[21]\tvalidation-gamma-nloglik:3.63727\n",
      "[22]\tvalidation-gamma-nloglik:3.60982\n",
      "[23]\tvalidation-gamma-nloglik:3.58546\n",
      "[24]\tvalidation-gamma-nloglik:3.56389\n",
      "[25]\tvalidation-gamma-nloglik:3.54481\n",
      "[26]\tvalidation-gamma-nloglik:3.52797\n",
      "[27]\tvalidation-gamma-nloglik:3.51313\n",
      "[28]\tvalidation-gamma-nloglik:3.50007\n",
      "[29]\tvalidation-gamma-nloglik:3.48859\n",
      "[30]\tvalidation-gamma-nloglik:3.47852\n",
      "[31]\tvalidation-gamma-nloglik:3.46972\n",
      "[32]\tvalidation-gamma-nloglik:3.46203\n",
      "[33]\tvalidation-gamma-nloglik:3.45528\n",
      "[34]\tvalidation-gamma-nloglik:3.44940\n",
      "[35]\tvalidation-gamma-nloglik:3.44428\n",
      "[36]\tvalidation-gamma-nloglik:3.43983\n",
      "[37]\tvalidation-gamma-nloglik:3.43598\n",
      "[38]\tvalidation-gamma-nloglik:3.43262\n",
      "[39]\tvalidation-gamma-nloglik:3.42973\n",
      "[40]\tvalidation-gamma-nloglik:3.42722\n",
      "[41]\tvalidation-gamma-nloglik:3.42505\n",
      "[42]\tvalidation-gamma-nloglik:3.42318\n",
      "[43]\tvalidation-gamma-nloglik:3.42157\n",
      "[44]\tvalidation-gamma-nloglik:3.42019\n",
      "[45]\tvalidation-gamma-nloglik:3.41900\n",
      "[46]\tvalidation-gamma-nloglik:3.41799\n",
      "[47]\tvalidation-gamma-nloglik:3.41712\n",
      "[48]\tvalidation-gamma-nloglik:3.41636\n",
      "[49]\tvalidation-gamma-nloglik:3.41572\n",
      "[50]\tvalidation-gamma-nloglik:3.41517\n",
      "[51]\tvalidation-gamma-nloglik:3.41469\n",
      "[52]\tvalidation-gamma-nloglik:3.41429\n",
      "[53]\tvalidation-gamma-nloglik:3.41395\n",
      "[54]\tvalidation-gamma-nloglik:3.41366\n",
      "[55]\tvalidation-gamma-nloglik:3.41340\n",
      "[56]\tvalidation-gamma-nloglik:3.41319\n",
      "[57]\tvalidation-gamma-nloglik:3.41302\n",
      "[58]\tvalidation-gamma-nloglik:3.41286\n",
      "[59]\tvalidation-gamma-nloglik:3.41274\n",
      "[60]\tvalidation-gamma-nloglik:3.41263\n",
      "[61]\tvalidation-gamma-nloglik:3.41255\n",
      "[62]\tvalidation-gamma-nloglik:3.41247\n",
      "[63]\tvalidation-gamma-nloglik:3.41241\n",
      "[64]\tvalidation-gamma-nloglik:3.41235\n",
      "[65]\tvalidation-gamma-nloglik:3.41232\n",
      "[66]\tvalidation-gamma-nloglik:3.41228\n",
      "[67]\tvalidation-gamma-nloglik:3.41225\n",
      "[68]\tvalidation-gamma-nloglik:3.41223\n",
      "[69]\tvalidation-gamma-nloglik:3.41222\n",
      "[70]\tvalidation-gamma-nloglik:3.41222\n",
      "[71]\tvalidation-gamma-nloglik:3.41221\n",
      "[72]\tvalidation-gamma-nloglik:3.41219\n",
      "[73]\tvalidation-gamma-nloglik:3.41218\n",
      "[74]\tvalidation-gamma-nloglik:3.41217\n",
      "[75]\tvalidation-gamma-nloglik:3.41215\n",
      "[76]\tvalidation-gamma-nloglik:3.41215\n",
      "[77]\tvalidation-gamma-nloglik:3.41215\n",
      "[78]\tvalidation-gamma-nloglik:3.41214\n",
      "[79]\tvalidation-gamma-nloglik:3.41215\n",
      "[80]\tvalidation-gamma-nloglik:3.41215\n",
      "[81]\tvalidation-gamma-nloglik:3.41214\n",
      "[82]\tvalidation-gamma-nloglik:3.41214\n",
      "[83]\tvalidation-gamma-nloglik:3.41214\n",
      "[84]\tvalidation-gamma-nloglik:3.41214\n",
      "[85]\tvalidation-gamma-nloglik:3.41214\n",
      "[86]\tvalidation-gamma-nloglik:3.41214\n",
      "[87]\tvalidation-gamma-nloglik:3.41214\n",
      "[88]\tvalidation-gamma-nloglik:3.41214\n",
      "[89]\tvalidation-gamma-nloglik:3.41214\n",
      "[90]\tvalidation-gamma-nloglik:3.41214\n",
      "[91]\tvalidation-gamma-nloglik:3.41214\n",
      "[92]\tvalidation-gamma-nloglik:3.41215\n",
      "[93]\tvalidation-gamma-nloglik:3.41215\n",
      "[94]\tvalidation-gamma-nloglik:3.41215\n",
      "[95]\tvalidation-gamma-nloglik:3.41216\n",
      "[96]\tvalidation-gamma-nloglik:3.41216\n",
      "[97]\tvalidation-gamma-nloglik:3.41216\n",
      "[98]\tvalidation-gamma-nloglik:3.41217\n",
      "[99]\tvalidation-gamma-nloglik:3.41218\n",
      "[100]\tvalidation-gamma-nloglik:3.41218\n",
      "[101]\tvalidation-gamma-nloglik:3.41218\n",
      "[102]\tvalidation-gamma-nloglik:3.41218\n",
      "[103]\tvalidation-gamma-nloglik:3.41218\n",
      "[104]\tvalidation-gamma-nloglik:3.41218\n",
      "[105]\tvalidation-gamma-nloglik:3.41218\n",
      "[106]\tvalidation-gamma-nloglik:3.41218\n",
      "[107]\tvalidation-gamma-nloglik:3.41218\n",
      "[108]\tvalidation-gamma-nloglik:3.41218\n",
      "[109]\tvalidation-gamma-nloglik:3.41219\n",
      "[110]\tvalidation-gamma-nloglik:3.41220\n",
      "[111]\tvalidation-gamma-nloglik:3.41220\n",
      "[112]\tvalidation-gamma-nloglik:3.41219\n",
      "[113]\tvalidation-gamma-nloglik:3.41220\n",
      "[114]\tvalidation-gamma-nloglik:3.41220\n",
      "[115]\tvalidation-gamma-nloglik:3.41220\n",
      "[116]\tvalidation-gamma-nloglik:3.41220\n",
      "[117]\tvalidation-gamma-nloglik:3.41220\n",
      "[118]\tvalidation-gamma-nloglik:3.41220\n",
      "[119]\tvalidation-gamma-nloglik:3.41221\n",
      "[120]\tvalidation-gamma-nloglik:3.41222\n",
      "[121]\tvalidation-gamma-nloglik:3.41222\n",
      "[122]\tvalidation-gamma-nloglik:3.41221\n",
      "[123]\tvalidation-gamma-nloglik:3.41223\n",
      "[124]\tvalidation-gamma-nloglik:3.41223\n",
      "[125]\tvalidation-gamma-nloglik:3.41223\n",
      "[126]\tvalidation-gamma-nloglik:3.41223\n",
      "[127]\tvalidation-gamma-nloglik:3.41223\n",
      "[128]\tvalidation-gamma-nloglik:3.41223\n",
      "[129]\tvalidation-gamma-nloglik:3.41224\n",
      "[130]\tvalidation-gamma-nloglik:3.41224\n",
      "[131]\tvalidation-gamma-nloglik:3.41225\n",
      "[132]\tvalidation-gamma-nloglik:3.41226\n",
      "[133]\tvalidation-gamma-nloglik:3.41226\n",
      "[134]\tvalidation-gamma-nloglik:3.41226\n",
      "[135]\tvalidation-gamma-nloglik:3.41226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/25 17:15:59 WARNING mlflow.xgboost: Failed to infer model signature: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:trip_type: category, RatecodeID: category\n",
      "2024/07/25 17:15:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/bruno/anaconda3/envs/MLOps/lib/python3.12/site-packages/xgboost/core.py:160: UserWarning: [17:15:59] WARNING: /croot/xgboost-split_1713972711803/work/cpp_src/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\"\n",
      "2024/07/25 17:15:59 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during xgboost autologging: [17:15:59] /croot/xgboost-split_1713972711803/work/cpp_src/src/tree/tree_model.cc:899: Check failed: !HasCategoricalSplit(): Please use JSON/UBJSON for saving models with categorical splits.\n",
      "Stack trace:\n",
      "  [bt] (0) /home/bruno/anaconda3/envs/MLOps/lib/libxgboost.so(+0x109124) [0x7c4ae8509124]\n",
      "  [bt] (1) /home/bruno/anaconda3/envs/MLOps/lib/libxgboost.so(xgboost::RegTree::Save(dmlc::Stream*) const+0x4fe) [0x7c4ae8a68d4e]\n",
      "  [bt] (2) /home/bruno/anaconda3/envs/MLOps/lib/libxgboost.so(xgboost::gbm::GBTreeModel::Save(dmlc::Stream*) const+0x238) [0x7c4ae8828128]\n",
      "  [bt] (3) /home/bruno/anaconda3/envs/MLOps/lib/libxgboost.so(+0x442a6e) [0x7c4ae8842a6e]\n",
      "  [bt] (4) /home/bruno/anaconda3/envs/MLOps/lib/libxgboost.so(XGBoosterSaveModel+0x482) [0x7c4ae85120a2]\n",
      "  [bt] (5) /home/bruno/anaconda3/envs/MLOps/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x7c4b30623052]\n",
      "  [bt] (6) /home/bruno/anaconda3/envs/MLOps/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x7c4b30621925]\n",
      "  [bt] (7) /home/bruno/anaconda3/envs/MLOps/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7c4b3062206e]\n",
      "  [bt] (8) /home/bruno/anaconda3/envs/MLOps/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x97b7) [0x7c4b303e87b7]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_final = {\n",
    " 'learning_rate': 0.08055973081693549,\n",
    " 'max_depth': int(4),\n",
    " 'min_child_weight': 15.76289220268423,\n",
    " 'reg_alpha': 0.10079556317337575,\n",
    " 'reg_lambda': 0.04834019493231889,\n",
    " 'objective': 'reg:gamma',\n",
    " 'seed': 42,\n",
    " 'eval_metric': 'gamma-nloglik'}\n",
    "\n",
    "\n",
    "# Autologging is known to be compatible with the following package versions: 1.4.2 <= xgboost <= 2.0.3. \n",
    "# Autologging may not succeed when used with package versions outside of this range.\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.xgboost.autolog()\n",
    "\n",
    "    train = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "    valid = xgb.DMatrix(X_val,   label=y_val,   enable_categorical=True)\n",
    "    test = xgb.DMatrix(X_test,   label=y_test,  enable_categorical=True)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=params_final,\n",
    "        dtrain=train,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(valid, 'validation')],\n",
    "        early_stopping_rounds=50\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
